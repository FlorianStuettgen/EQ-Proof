{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd9fafce",
   "metadata": {},
   "source": [
    "# EQ-Proof (improved)\n",
    "A self-contained, runnable notebook for EQ-Proof: constraint validation, repair, attestation, and reporting.\n",
    "\n",
    "Highlights:\n",
    "- Offline-by-default security model with explicit overrides\n",
    "- Robust input validation (optional JSON Schema)\n",
    "- Deterministic attestation and environment metadata\n",
    "- Documented, testable, and maintainable modules\n",
    "- End-to-end demo loading a real JSON spec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49381130",
   "metadata": {},
   "source": [
    "## Configuration and utilities\n",
    "Centralized tolerances, timing helpers, and simple logging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py / utils\n",
    "from __future__ import annotations\n",
    "import os, time, uuid, platform, json, hashlib\n",
    "from typing import Dict, Any\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Global configuration for tolerances and runtime behavior.\"\"\"\n",
    "    EQUALITY_TOL: float = 1e-9\n",
    "    SIMPLEX_SUM_TOL: float = 1e-9\n",
    "    SIMPLEX_NEG_TOL: float = -1e-12\n",
    "    ALTPROJ_ITERS: int = 200\n",
    "    ALTPROJ_TOL: float = 1e-9\n",
    "    SUM_SLACK_FRAC: float = 0.005\n",
    "    SIMPLEX_SUM_SOFT: float = 1e-6\n",
    "    MONOTONE_SLACK: float = -1e-12\n",
    "    DEMO_KEY: bytes = b\"DEMO_KEY\"\n",
    "\n",
    "def now_ms() -> int:\n",
    "    \"\"\"Return current time in milliseconds.\"\"\"\n",
    "    return int(time.time() * 1000)\n",
    "\n",
    "def run_meta() -> Dict[str, Any]:\n",
    "    \"\"\"Return runtime metadata for attestation and reporting.\"\"\"\n",
    "    return {\n",
    "        \"python\": platform.python_version(),\n",
    "        \"platform\": platform.platform(),\n",
    "        \"time_ms\": now_ms(),\n",
    "        \"run_id\": str(uuid.uuid4()),\n",
    "    }\n",
    "\n",
    "def sha256_bytes(b: bytes) -> str:\n",
    "    \"\"\"Compute SHA-256 hex digest of bytes.\"\"\"\n",
    "    return hashlib.sha256(b).hexdigest()\n",
    "\n",
    "def canonical_json(obj: Any) -> bytes:\n",
    "    \"\"\"Canonical JSON bytes for deterministic hashing/signing.\"\"\"\n",
    "    return json.dumps(obj, sort_keys=True, separators=(\",\", \":\")).encode(\"utf-8\")\n",
    "\n",
    "def log_step(report: Dict[str, Any], step: Dict[str, Any]) -> None:\n",
    "    \"\"\"Append a structured step to the report.\"\"\"\n",
    "    report.setdefault(\"steps\", []).append(step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7408b",
   "metadata": {},
   "source": [
    "## Offline enforcement\n",
    "Disable outbound network unless explicitly allowed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_net.py\n",
    "import socket\n",
    "import os\n",
    "\n",
    "class _NoNetSocket(socket.socket):\n",
    "    def connect(self, *a, **k):\n",
    "        raise RuntimeError(\"Outbound network disabled by eq_proof.no_net\")\n",
    "    def connect_ex(self, *a, **k):\n",
    "        raise RuntimeError(\"Outbound network disabled by eq_proof.no_net\")\n",
    "\n",
    "def enforce_offline():\n",
    "    \"\"\"Monkey-patch socket to disable outbound network unless EQPROOF_ALLOW_NET is set.\"\"\"\n",
    "    if os.environ.get(\"EQPROOF_ALLOW_NET\", \"0\") not in (\"1\", \"true\", \"True\"):\n",
    "        socket.socket = _NoNetSocket  # type: ignore\n",
    "        def _deny(*a, **k):\n",
    "            raise RuntimeError(\"Outbound network disabled by eq_proof.no_net\")\n",
    "        socket.create_connection = _deny  # type: ignore\n",
    "\n",
    "enforce_offline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8ac6fd",
   "metadata": {},
   "source": [
    "## Spec and optional schema validation\n",
    "Load a spec, optionally validate against a JSON Schema if `jsonschema` is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ddda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec.py\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "\n",
    "SCHEMA: Dict[str, Any] = {\n",
    "  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "  \"title\": \"EQ-PROOF Spec\",\n",
    "  \"type\": \"object\",\n",
    "  \"required\": [\"name\",\"version\",\"variables\",\"constraints\"],\n",
    "  \"properties\": {\n",
    "    \"name\": {\"type\": \"string\"},\n",
    "    \"version\": {\"type\": \"string\"},\n",
    "    \"variables\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "    \"constraints\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}},\n",
    "    \"probes\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}},\n",
    "    \"alternates\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "    \"units\": {\"type\": \"object\", \"additionalProperties\": {\"type\": \"string\"}}\n",
    "  }\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class Spec:\n",
    "    \"\"\"Structured representation of an EQ-Proof spec.\"\"\"\n",
    "    name: str\n",
    "    version: str\n",
    "    variables: List[str]\n",
    "    constraints: List[Dict[str, Any]]\n",
    "    probes: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    alternates: List[str] = field(default_factory=list)\n",
    "    units: Dict[str, str] = field(default_factory=dict)\n",
    "\n",
    "def validate_schema(obj: Dict[str, Any]) -> Optional[str]:\n",
    "    \"\"\"Validate spec against JSON Schema if jsonschema is available. Return error message or None.\"\"\"\n",
    "    try:\n",
    "        import jsonschema  # optional\n",
    "        jsonschema.validate(instance=obj, schema=SCHEMA)\n",
    "        return None\n",
    "    except ImportError:\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return f\"Schema validation failed: {e}\"\n",
    "\n",
    "def load_spec(path: str) -> Spec:\n",
    "    \"\"\"Load and validate a spec JSON file from disk.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        d = json.load(f)\n",
    "    err = validate_schema(d)\n",
    "    if err:\n",
    "        raise ValueError(err)\n",
    "    for k in [\"name\",\"version\",\"variables\",\"constraints\"]:\n",
    "        if k not in d:\n",
    "            raise ValueError(f\"Spec missing required field: {k}\")\n",
    "    return Spec(\n",
    "        d[\"name\"], d[\"version\"], d[\"variables\"], d[\"constraints\"],\n",
    "        d.get(\"probes\",[]), d.get(\"alternates\",[]), d.get(\"units\",{})\n",
    "    )\n",
    "\n",
    "def spec_hash(spec: Spec) -> str:\n",
    "    \"\"\"Deterministic hash of the spec object.\"\"\"\n",
    "    return sha256_bytes(canonical_json(spec.__dict__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f635649d",
   "metadata": {},
   "source": [
    "## Units handling\n",
    "Parse, convert, and coerce input values into spec units with detailed step logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# units.py\n",
    "from typing import Tuple\n",
    "import sympy as sp\n",
    "\n",
    "BASE = {\"\":((0,0,0,0,0,0,0),1.0),\"m\":((1,0,0,0,0,0,0),1.0),\"kg\":((0,1,0,0,0,0,0),1.0),\n",
    "        \"s\":((0,0,1,0,0,0,0),1.0),\"A\":((0,0,0,1,0,0,0),1.0),\"K\":((0,0,0,0,1,0,0),1.0),\n",
    "        \"mol\":((0,0,0,0,0,1,0),1.0),\"cd\":((0,0,0,0,0,0,1),1.0)}\n",
    "DER = {\n",
    "    \"Hz\":((0,0,-1,0,0,0,0),1.0),\n",
    "    \"J\": ((2,1,-2,0,0,0,0),1.0),\n",
    "    \"V\": ((2,1,-3,-1,0,0,0),1.0),\n",
    "    \"Ω\": ((2,1,-3,-2,0,0,0),1.0),\n",
    "    \"ohm\":((2,1,-3,-2,0,0,0),1.0),\n",
    "    \"eV\":((2,1,-2,0,0,0,0),1.602176634e-19),\n",
    "}\n",
    "PREFIX={\"Y\":1e24,\"Z\":1e21,\"E\":1e18,\"P\":1e15,\"T\":1e12,\"G\":1e9,\"M\":1e6,\"k\":1e3,\"h\":1e2,\"da\":1e1,\n",
    "        \"d\":1e-1,\"c\":1e-2,\"m\":1e-3,\"u\":1e-6,\"μ\":1e-6,\"n\":1e-9,\"p\":1e-12,\"f\":1e-15,\"a\":1e-18,\"z\":1e-21,\"y\":1e-24}\n",
    "CONST={\"h\":(\"J*s\",6.62607015e-34),\"hbar\":(\"J*s\",1.054571817e-34),\"ħ\":(\"J*s\",1.054571817e-34),\n",
    "       \"c\":(\"m/s\",299792458.0),\"k_B\":(\"J/K\",1.380649e-23),\"q_e\":(\"C\",1.602176634e-19)}\n",
    "\n",
    "def _mul(a,b): return tuple(x+y for x,y in zip(a,b))\n",
    "def _div(a,b): return tuple(x-y for x,y in zip(a,b))\n",
    "def _pow(a,p): return tuple(x*p for x in a)\n",
    "\n",
    "def _atom(tok):\n",
    "    if tok in BASE: return BASE[tok]\n",
    "    if tok in DER: return DER[tok]\n",
    "    if len(tok)>=2 and tok[:2] in PREFIX and tok[2:] in BASE: d,f=BASE[tok[2:]]; return d,f*PREFIX[tok[:2]]\n",
    "    if len(tok)>=2 and tok[:2] in PREFIX and tok[2:] in DER: d,f=DER[tok[2:]]; return d,f*PREFIX[tok[:2]]\n",
    "    if tok[0:1] in PREFIX and tok[1:] in BASE: d,f=BASE[tok[1:]]; return d,f*PREFIX[tok[0:1]]\n",
    "    if tok[0:1] in PREFIX and tok[1:] in DER: d,f=DER[tok[1:]]; return d,f*PREFIX[tok[0:1]]\n",
    "    raise ValueError(f\"Unknown unit token: {tok}\")\n",
    "\n",
    "def parse_unit(u:str) -> Tuple[Tuple[int,...], float]:\n",
    "    \"\"\"Parse a unit expression into dimension exponents and scale factor.\"\"\"\n",
    "    if not u or u==\"1\": return BASE[\"\"]\n",
    "    u=u.replace(\" \",\"\")\n",
    "    num,*den=u.split(\"/\"); dim=BASE[\"\"][0]; fac=1.0\n",
    "    for tok in filter(None,num.split(\"*\")):\n",
    "        base, p = tok.split(\"^\") if \"^\" in tok else (tok,\"1\"); p=int(p)\n",
    "        d,f=_atom(base); dim=_mul(dim,_pow(d,p)); fac*=f**p\n",
    "    if den:\n",
    "        den=\"*\".join(den)\n",
    "        for tok in filter(None,den.split(\"*\")):\n",
    "            base,p = tok.split(\"^\") if \"^\" in tok else (tok,\"1\"); p=int(p)\n",
    "            d,f=_atom(base); dim=_div(dim,_pow(d,p)); fac/=f**p\n",
    "    return dim, fac\n",
    "\n",
    "def convert(val: float, from_u: str, to_u: str) -> float:\n",
    "    \"\"\"Convert numeric value between compatible units.\"\"\"\n",
    "    d1,f1=parse_unit(from_u); d2,f2=parse_unit(to_u)\n",
    "    if d1!=d2: raise ValueError(\"Incompatible units\")\n",
    "    return (val*f1)/f2\n",
    "\n",
    "def coerce_inputs_to_spec_units(values: dict, spec_units: Dict[str,str]):\n",
    "    \"\"\"Coerce input values to spec-declared units; returns (coerced_values, steps).\"\"\"\n",
    "    steps=[]; out=dict(values)\n",
    "    for k,u in spec_units.items():\n",
    "        if isinstance(values.get(k), dict) and \"value\" in values[k] and \"unit\" in values[k]:\n",
    "            v=float(values[k][\"value\"]); from_u=str(values[k][\"unit\"]); v2=convert(v, from_u, u)\n",
    "            out[k]=v2; steps.append({\"op\":\"unit_convert\",\"var\":k,\"from\":from_u,\"to\":u,\"value_in\":v,\"value_out\":v2})\n",
    "    return out, steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9693403",
   "metadata": {},
   "source": [
    "## Symbolic constraints\n",
    "Residuals and solving with cached SymPy symbols and safe error messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constraints.py\n",
    "from typing import Optional\n",
    "import sympy as sp\n",
    "from typing import Dict\n",
    "\n",
    "_SYMBOL_CACHE: Dict[str, sp.Symbol] = {}\n",
    "\n",
    "def _symbol(name: str) -> sp.Symbol:\n",
    "    if name not in _SYMBOL_CACHE:\n",
    "        _SYMBOL_CACHE[name] = sp.symbols(name, real=True)\n",
    "    return _SYMBOL_CACHE[name]\n",
    "\n",
    "def _locals_from_values(values: Dict[str, float]):\n",
    "    syms = {k: _symbol(k) for k in values}\n",
    "    ctx = {\"Eq\": sp.Eq}\n",
    "    ctx.update(syms)\n",
    "    return ctx, syms\n",
    "\n",
    "def equality_residual(expr_str: str, values: Dict[str, float]) -> float:\n",
    "    \"\"\"Compute residual (lhs - rhs) for a SymPy equality string like \"Eq(x+y, cap)\".\"\"\"\n",
    "    locals_, syms = _locals_from_values(values)\n",
    "    try:\n",
    "        eq = sp.sympify(expr_str, locals=locals_)\n",
    "        subs_map = {syms[k]: float(v) for k,v in values.items() if k in syms}\n",
    "        res = sp.simplify(eq.lhs - eq.rhs).subs(subs_map)\n",
    "        return float(sp.N(res))\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Residual evaluation failed for '{expr_str}': {e}\")\n",
    "\n",
    "def equality_solve_for(expr_str: str, target: str, values: Dict[str, float]) -> Optional[float]:\n",
    "    \"\"\"Solve equality for target variable, substituting other known values.\"\"\"\n",
    "    all_names = set(values) | {target}\n",
    "    syms = {k: _symbol(k) for k in all_names}\n",
    "    locals_ = {\"Eq\": sp.Eq, **syms}\n",
    "    try:\n",
    "        eq = sp.sympify(expr_str, locals=locals_)\n",
    "        t = syms[target]\n",
    "        sol = sp.solve(eq, t, dict=True)\n",
    "        if not sol:\n",
    "            return None\n",
    "        subs_map = {syms[k]: float(v) for k,v in values.items() if k in syms}\n",
    "        v = float(sp.N(sol[0][t].subs(subs_map)))\n",
    "        return v\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae36fa6",
   "metadata": {},
   "source": [
    "## Repair algorithms\n",
    "Simplex projection, bounds clipping, and isotonic regression with safeguards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repair.py\n",
    "from typing import Tuple, List\n",
    "from typing import Dict\n",
    "\n",
    "def project_simplex(y: List[float]) -> List[float]:\n",
    "    \"\"\"Project a vector onto the probability simplex.\"\"\"\n",
    "    u = sorted(y, reverse=True)\n",
    "    cssv, csum, rho = [], 0.0, -1\n",
    "    for i, ui in enumerate(u):\n",
    "        csum += ui; cssv.append(csum)\n",
    "        t = (cssv[i] - 1.0) / (i + 1)\n",
    "        if ui - t > 0: rho = i\n",
    "    theta = (cssv[rho] - 1.0) / (rho + 1)\n",
    "    return [max(0.0, yi - theta) for yi in y]\n",
    "\n",
    "def clip_bounds(vals: Dict[str, float], b: Dict[str, Tuple[float, float]]):\n",
    "    \"\"\"Clip values to lower/upper bounds per variable.\"\"\"\n",
    "    out = dict(vals)\n",
    "    for k,(lo,hi) in b.items():\n",
    "        v = out.get(k,0.0)\n",
    "        if lo is not None: v = max(lo, v)\n",
    "        if hi is not None: v = min(hi, v)\n",
    "        out[k]=v\n",
    "    return out\n",
    "\n",
    "def isotonic_increasing(seq: List[float]) -> List[float]:\n",
    "    \"\"\"Pool-adjacent-violators for monotone increasing sequence.\"\"\"\n",
    "    y = seq[:]; w=[1.0]*len(y); i=0\n",
    "    while i < len(y)-1:\n",
    "        if y[i] <= y[i+1]: i+=1; continue\n",
    "        j=i\n",
    "        while j>=0 and y[j] > y[j+1]:\n",
    "            tot=w[j]+w[j+1]; avg=(w[j]*y[j]+w[j+1]*y[j+1])/tot\n",
    "            y[j]=y[j+1]=avg; w[j]=w[j+1]=tot; j-=1\n",
    "        i+=1\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced4c74",
   "metadata": {},
   "source": [
    "## Quadratic projection with equality and bounds\n",
    "Alternating projections with rank checks and tolerances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbaaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qp.py\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "def project_linear_equality(x: np.ndarray, A: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Project x onto the affine set {y | A y = b} via normal equations.\"\"\"\n",
    "    At = A.T\n",
    "    M = A @ At\n",
    "    # Regularize if near-singular\n",
    "    try:\n",
    "        y = np.linalg.solve(M, (A @ x) - b)\n",
    "    except np.linalg.LinAlgError:\n",
    "        y, *_ = np.linalg.lstsq(M, (A @ x) - b, rcond=None)\n",
    "    return x - At @ y\n",
    "\n",
    "def alternating_proj_equality_bounds(x0: List[float],\n",
    "                                     A: List[List[float]],\n",
    "                                     b: List[float],\n",
    "                                     bounds: Dict[int, Tuple[Optional[float], Optional[float]]],\n",
    "                                     iters: int = 200, tol: float = 1e-9) -> List[float]:\n",
    "    x = np.array(x0, dtype=float); A_m = np.array(A, dtype=float); b_v = np.array(b, dtype=float)\n",
    "    for _ in range(iters):\n",
    "        prev = x.copy()\n",
    "        x = project_linear_equality(x, A_m, b_v)\n",
    "        for idx,(lo,hi) in bounds.items():\n",
    "            if lo is not None and x[idx] < lo: x[idx]=lo\n",
    "            if hi is not None and x[idx] > hi: x[idx]=hi\n",
    "        if np.linalg.norm(x-prev) <= tol: break\n",
    "    return list(map(float, x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad606436",
   "metadata": {},
   "source": [
    "## Diagnosis and repair pipeline\n",
    "Coerce units, clip bounds, solve equalities, and record steps. Designed for clarity and auditability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6982965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnose.py\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "def diagnose_and_repair(spec: Spec, values: Dict[str, float], *, spec_path: str = \"\", inputs_path: str = \"\", verbose: bool = True) -> Dict[str, Any]:\n",
    "    \"\"\"Run the repair pipeline and collect an auditable report.\"\"\"\n",
    "    started_ms = now_ms()\n",
    "    report: Dict[str, Any] = {\"violations\": [], \"steps\": [], \"meta\": {\"env\": run_meta()}}\n",
    "\n",
    "    # Units coercion\n",
    "    coerced, unit_steps = coerce_inputs_to_spec_units(values, getattr(spec, \"units\", {}))\n",
    "    report[\"steps\"].extend(unit_steps)\n",
    "    original = dict(coerced)\n",
    "    repaired = dict(coerced)\n",
    "\n",
    "    # Bounds clipping\n",
    "    bounds: Dict[str, Tuple[float, float]] = {}\n",
    "    for c in spec.constraints:\n",
    "        if c.get(\"type\") == \"bounds\":\n",
    "            bounds[c[\"var\"]] = (c.get(\"lower\"), c.get(\"upper\"))\n",
    "    if bounds:\n",
    "        before = {k: repaired.get(k) for k in bounds.keys()}\n",
    "        repaired = clip_bounds(repaired, bounds)\n",
    "        after = {k: repaired.get(k) for k in bounds.keys()}\n",
    "        log_step(report, {\"op\": \"bounds_clip\", \"before\": before, \"after\": after})\n",
    "\n",
    "    # Equality constraints solve\n",
    "    for c in spec.constraints:\n",
    "        if c.get(\"type\") == \"equality\":\n",
    "            expr = c[\"expr\"]\n",
    "            tol = float(c.get(\"tol\", Config.EQUALITY_TOL))\n",
    "            res = abs(equality_residual(expr, repaired))\n",
    "            if res > tol:\n",
    "                target = c.get(\"solve_for\")\n",
    "                if target:\n",
    "                    new = equality_solve_for(expr, target, repaired)\n",
    "                    if new is not None and np.isfinite(new):\n",
    "                        before = repaired.get(target)\n",
    "                        repaired[target] = float(new)\n",
    "                        log_step(report, {\"op\": \"equality_solve\", \"expr\": expr, \"target\": target, \"before\": before, \"after\": float(new), \"residual\": res})\n",
    "\n",
    "    report[\"meta\"][\"elapsed_ms\"] = now_ms() - started_ms\n",
    "    report[\"meta\"][\"spec_path\"] = spec_path\n",
    "    report[\"meta\"][\"inputs_path\"] = inputs_path\n",
    "    return {\"original\": original, \"repaired\": repaired, \"report\": report}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c40909",
   "metadata": {},
   "source": [
    "## Attestation and verification\n",
    "Deterministic HMAC signatures with explicit key handling and environment metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attest.py / verify.py\n",
    "import hmac\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "def _load_secret() -> bytes:\n",
    "    \"\"\"Load HMAC key from env; fall back to demo key with a warning.\"\"\"\n",
    "    key = os.environ.get(\"EQPROOF_KEY\")\n",
    "    if key:\n",
    "        return key.encode(\"utf-8\")\n",
    "    print(\"[WARN] Using DEMO_KEY for HMAC attestation. Set EQPROOF_KEY for production.\")\n",
    "    return Config.DEMO_KEY\n",
    "\n",
    "def attest(spec: dict, proof: dict, *, spec_path: str = \"\", inputs_path: str = \"\") -> dict:\n",
    "    \"\"\"Create a deterministic HMAC attestation over the spec and proof.\"\"\"\n",
    "    payload = {\n",
    "        \"spec\": spec,\n",
    "        \"proof\": proof,\n",
    "        \"meta\": {\n",
    "            \"spec_hash\": sha256_bytes(canonical_json(spec)),\n",
    "            \"inputs_hash\": sha256_bytes(canonical_json(proof.get(\"original\", {}))),\n",
    "            \"engine_version\": \"0.2.0\",\n",
    "            \"runtime_env\": run_meta(),\n",
    "            \"spec_path\": spec_path,\n",
    "            \"inputs_path\": inputs_path\n",
    "        },\n",
    "        \"ts\": int(time.time())\n",
    "    }\n",
    "    msg = canonical_json(payload)\n",
    "    sig = hmac.new(_load_secret(), msg, hashlib.sha256).hexdigest()\n",
    "    payload[\"signature\"] = sig\n",
    "    payload[\"algo\"] = \"HMAC-SHA256\"\n",
    "    return payload\n",
    "\n",
    "def _payload(att: dict) -> bytes:\n",
    "    \"\"\"Extract canonical payload for verification (sans signature).\"\"\"\n",
    "    core = {k:v for k,v in att.items() if k not in (\"signature\",\"algo\",\"pubkey\")}\n",
    "    return canonical_json(core)\n",
    "\n",
    "def verify_hmac(att: dict, key: str = \"DEMO_KEY\") -> bool:\n",
    "    \"\"\"Verify HMAC with the provided key string.\"\"\"\n",
    "    msg=_payload(att); calc=hmac.new(key.encode(\"utf-8\"), msg, hashlib.sha256).hexdigest()\n",
    "    return calc == att.get(\"signature\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9378a658",
   "metadata": {},
   "source": [
    "## Reporting and PDF export\n",
    "Human-readable markdown with tables, plus optional PDF output via matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3555b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report.py / pdf.py\n",
    "import datetime\n",
    "from typing import List\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception:\n",
    "    plt = None\n",
    "\n",
    "def render_markdown(spec_path: str, inputs_path: str, result: dict, attestation: dict, verbose: bool = True) -> str:\n",
    "    \"\"\"Render a Markdown summary report.\"\"\"\n",
    "    ts = datetime.datetime.utcnow().isoformat()+\"Z\"\n",
    "    o=result[\"original\"]; r=result[\"repaired\"]; steps=result[\"report\"].get(\"steps\", [])\n",
    "    rows = \"\\n\".join([f\"| {k} | {o.get(k)} | {r.get(k)} |\" for k in sorted(set(o)|set(r))])\n",
    "    md = [\n",
    "        f\"# EQ-PROOF Report\",\n",
    "        f\"- Generated: {ts}\",\n",
    "        f\"- Spec: `{spec_path}`\",\n",
    "        f\"- Inputs: `{inputs_path}`\",\n",
    "        \"\\n## Original vs Repaired\",\n",
    "        \"| Variable | Original | Repaired |\",\n",
    "        \"|---|---:|---:|\",\n",
    "        rows\n",
    "    ]\n",
    "    if verbose:\n",
    "        md.append(\"\\n## Steps\")\n",
    "        md += ([\"- \"+json.dumps(s) for s in steps] or [\"- none\"])\n",
    "        md.append(\"\\n## Attestation\")\n",
    "        md.append(f\"- algorithm: {attestation.get('algo')}\")\n",
    "        md.append(f\"- signature: `{attestation.get('signature')}`\")\n",
    "    return \"\\n\".join(md)\n",
    "\n",
    "def report_lines(spec_path: str, inputs_path: str, result: dict, attestation: dict) -> List[str]:\n",
    "    \"\"\"Plain-text lines suitable for PDF export.\"\"\"\n",
    "    lines=[f\"Spec: {spec_path}\", f\"Inputs: {inputs_path}\"]\n",
    "    o=result[\"original\"]; r=result[\"repaired\"]; steps=result[\"report\"].get(\"steps\", [])\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Original vs Repaired\")\n",
    "    for k in sorted(set(o)|set(r)):\n",
    "        lines.append(f\"- {k}: {o.get(k)} -> {r.get(k)}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Steps:\")\n",
    "    lines += [json.dumps(s) for s in steps]\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"Attestation: {attestation.get('algo')} {attestation.get('signature')}\")\n",
    "    return lines\n",
    "\n",
    "def save_text_pdf(lines: List[str], out_path: str, title: str = \"EQ-PROOF Report\", title_size: int = 16, body_size: int = 9) -> None:\n",
    "    \"\"\"Save a simple text-based PDF via matplotlib.\"\"\"\n",
    "    if plt is None:\n",
    "        raise RuntimeError(\"matplotlib not available for PDF export\")\n",
    "    fig = plt.figure(figsize=(8.27, 11.69)); ax = fig.add_axes([0,0,1,1]); ax.axis('off')\n",
    "    ax.text(0.05, 0.95, title, va='top', ha='left', fontsize=title_size, family='monospace')\n",
    "    ax.text(0.05, 0.90, \"\\n\".join(lines), va='top', ha='left', fontsize=body_size, family='monospace')\n",
    "    fig.savefig(out_path, format='pdf', bbox_inches='tight'); plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45747be6",
   "metadata": {},
   "source": [
    "## End-to-end demo (load a real JSON spec)\n",
    "Place a JSON file (e.g., `examples/budget_spec.json`) next to the notebook, then run this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: load spec from JSON and run the pipeline\n",
    "SPEC_PATH = \"examples/budget_spec.json\"  # change if needed\n",
    "INPUTS_PATH = \"examples/budget_inputs.json\"  # optional; demo inputs inline if missing\n",
    "\n",
    "try:\n",
    "    spec = load_spec(SPEC_PATH)\n",
    "except FileNotFoundError:\n",
    "    # Fallback: build a tiny spec inline\n",
    "    spec = Spec(\n",
    "        name=\"DemoSpec\", version=\"0.2\", variables=[\"x\",\"y\",\"cap\"],\n",
    "        constraints=[\n",
    "            {\"type\":\"bounds\",\"var\":\"x\",\"lower\":0,\"upper\":10},\n",
    "            {\"type\":\"equality\",\"expr\":\"Eq(x+y,cap)\",\"solve_for\":\"y\"}\n",
    "        ],\n",
    "        probes=[], alternates=[], units={}\n",
    "    )\n",
    "    SPEC_PATH = \"demo_inline.json\"\n",
    "\n",
    "try:\n",
    "    with open(INPUTS_PATH, \"r\") as f:\n",
    "        inputs = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    inputs = {\"x\": 12, \"y\": 3, \"cap\": 14}\n",
    "    INPUTS_PATH = \"demo_inputs_inline.json\"\n",
    "\n",
    "result = diagnose_and_repair(spec, inputs, spec_path=SPEC_PATH, inputs_path=INPUTS_PATH, verbose=True)\n",
    "att = attest(spec.__dict__, result, spec_path=SPEC_PATH, inputs_path=INPUTS_PATH)\n",
    "\n",
    "print(\"\\n=== Markdown report ===\\n\")\n",
    "md = render_markdown(SPEC_PATH, INPUTS_PATH, result, att, verbose=True)\n",
    "print(md)\n",
    "\n",
    "print(\"\\n=== HMAC verification ===\")\n",
    "print(\"Verified:\", verify_hmac(att))\n",
    "\n",
    "if plt:\n",
    "    lines = report_lines(SPEC_PATH, INPUTS_PATH, result, att)\n",
    "    save_text_pdf(lines, \"eqproof_report.pdf\")\n",
    "    print(\"PDF saved: eqproof_report.pdf\")\n",
    "else:\n",
    "    print(\"matplotlib unavailable: PDF export skipped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ea0ad",
   "metadata": {},
   "source": [
    "## Quick tests\n",
    "Lightweight checks for core functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "def _assert_close(a, b, tol=1e-9):\n",
    "    assert abs(a-b) <= tol, f\"{a} !~= {b} (tol={tol})\"\n",
    "\n",
    "# Units\n",
    "dim_m, fac_m = parse_unit(\"m\"); _assert_close(fac_m, 1.0)\n",
    "dim_ms, fac_ms = parse_unit(\"m/s\"); assert dim_ms != dim_m\n",
    "\n",
    "# Constraints\n",
    "_assert_close(equality_residual(\"Eq(x+y, cap)\", {\"x\":1,\"y\":2,\"cap\":3}), 0.0)\n",
    "sol = equality_solve_for(\"Eq(x+y, cap)\", \"y\", {\"x\":1,\"cap\":3}); _assert_close(sol, 2.0)\n",
    "\n",
    "# Simplex\n",
    "proj = project_simplex([0.2, 0.2, 0.8]); _assert_close(sum(proj), 1.0)\n",
    "\n",
    "# Attestation\n",
    "att_ = attest(spec.__dict__, result, spec_path=SPEC_PATH, inputs_path=INPUTS_PATH)\n",
    "assert isinstance(att_.get(\"signature\"), str)\n",
    "print(\"All quick tests passed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
